{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06123b27-ff34-4a73-ae1d-30a3b72a7616",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marin\\anaconda3\\envs\\autogluon\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# activate conda.yaml to setup autogluon environment prior to running code\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66a9f002-5ab0-4c6e-8c25-72f49472785c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the data\n",
    "# input_dataframe = pd.read_parquet('s3://cortex-dsc-2023-data/sprint_data/sprint_train.parquet')\n",
    "def create_dataframe(pt_path):\n",
    "        # Load the .pt file\n",
    "        data = torch.load(pt_path)\n",
    "\n",
    "        # Extract data into separate lists\n",
    "        pids, feats, labels = zip(*data)\n",
    "\n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame({\n",
    "            'pid': pids,\n",
    "            'label': labels,\n",
    "            'features': feats\n",
    "        })\n",
    "\n",
    "        feature_columns = [f'feature_{i}' for i in range(len(df['features'].iloc[0]))]\n",
    "\n",
    "         # Convert features column to a list of lists\n",
    "        df['features'] = df['features'].apply(lambda x: x.cpu().numpy().tolist())\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame(df['features'].tolist(), columns=feature_columns)], axis=1)\n",
    "\n",
    "        # Drop the original 'features' column\n",
    "        df = df.drop(columns=['features'])\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# os.chdir('./deepnote-gnn-reproduced-main')\n",
    "train_path = './data/discharge/train.pt'\n",
    "test_path = './data/discharge/test.pt'\n",
    "val_path = './data/discharge/val.pt'\n",
    "\n",
    "# Create DataFrames\n",
    "train_df = create_dataframe(train_path)\n",
    "test_df = create_dataframe(test_path)\n",
    "val_df = create_dataframe(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>label</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_758</th>\n",
       "      <th>feature_759</th>\n",
       "      <th>feature_760</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176176</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.175461</td>\n",
       "      <td>-0.031054</td>\n",
       "      <td>0.046837</td>\n",
       "      <td>0.136903</td>\n",
       "      <td>-0.117701</td>\n",
       "      <td>-0.026094</td>\n",
       "      <td>0.385239</td>\n",
       "      <td>0.094383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038490</td>\n",
       "      <td>-0.164991</td>\n",
       "      <td>0.030843</td>\n",
       "      <td>0.220228</td>\n",
       "      <td>-0.002753</td>\n",
       "      <td>-0.044868</td>\n",
       "      <td>-0.083309</td>\n",
       "      <td>0.076162</td>\n",
       "      <td>-0.344506</td>\n",
       "      <td>-0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176176</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.224407</td>\n",
       "      <td>0.036126</td>\n",
       "      <td>-0.086208</td>\n",
       "      <td>0.157155</td>\n",
       "      <td>-0.013275</td>\n",
       "      <td>-0.059862</td>\n",
       "      <td>0.433127</td>\n",
       "      <td>0.156739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016694</td>\n",
       "      <td>-0.313061</td>\n",
       "      <td>0.206523</td>\n",
       "      <td>0.293353</td>\n",
       "      <td>-0.120235</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>-0.026881</td>\n",
       "      <td>0.008423</td>\n",
       "      <td>-0.385576</td>\n",
       "      <td>0.023437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>161160</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.156343</td>\n",
       "      <td>-0.023782</td>\n",
       "      <td>0.068393</td>\n",
       "      <td>0.115051</td>\n",
       "      <td>-0.114274</td>\n",
       "      <td>-0.026454</td>\n",
       "      <td>0.369157</td>\n",
       "      <td>0.098631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027988</td>\n",
       "      <td>-0.165158</td>\n",
       "      <td>-0.019983</td>\n",
       "      <td>0.228936</td>\n",
       "      <td>-0.010385</td>\n",
       "      <td>-0.044965</td>\n",
       "      <td>-0.089852</td>\n",
       "      <td>0.107745</td>\n",
       "      <td>-0.332285</td>\n",
       "      <td>-0.018265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161160</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.037761</td>\n",
       "      <td>-0.072406</td>\n",
       "      <td>0.355639</td>\n",
       "      <td>0.025613</td>\n",
       "      <td>-0.312891</td>\n",
       "      <td>0.028596</td>\n",
       "      <td>0.250725</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065428</td>\n",
       "      <td>0.033266</td>\n",
       "      <td>-0.341756</td>\n",
       "      <td>0.153609</td>\n",
       "      <td>0.139355</td>\n",
       "      <td>-0.052577</td>\n",
       "      <td>-0.161805</td>\n",
       "      <td>0.319533</td>\n",
       "      <td>-0.246552</td>\n",
       "      <td>-0.104527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161160</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.169068</td>\n",
       "      <td>-0.042910</td>\n",
       "      <td>0.104977</td>\n",
       "      <td>0.132228</td>\n",
       "      <td>-0.105184</td>\n",
       "      <td>-0.033724</td>\n",
       "      <td>0.399281</td>\n",
       "      <td>0.078976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038849</td>\n",
       "      <td>-0.128436</td>\n",
       "      <td>-0.005195</td>\n",
       "      <td>0.239489</td>\n",
       "      <td>-0.026300</td>\n",
       "      <td>-0.040773</td>\n",
       "      <td>-0.107147</td>\n",
       "      <td>0.124502</td>\n",
       "      <td>-0.341689</td>\n",
       "      <td>-0.004925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pid  label  feature_0  feature_1  feature_2  feature_3  feature_4   \n",
       "0  176176      0  -0.175461  -0.031054   0.046837   0.136903  -0.117701  \\\n",
       "1  176176      0  -0.224407   0.036126  -0.086208   0.157155  -0.013275   \n",
       "2  161160      1  -0.156343  -0.023782   0.068393   0.115051  -0.114274   \n",
       "3  161160      1  -0.037761  -0.072406   0.355639   0.025613  -0.312891   \n",
       "4  161160      1  -0.169068  -0.042910   0.104977   0.132228  -0.105184   \n",
       "\n",
       "   feature_5  feature_6  feature_7  ...  feature_758  feature_759   \n",
       "0  -0.026094   0.385239   0.094383  ...     0.038490    -0.164991  \\\n",
       "1  -0.059862   0.433127   0.156739  ...     0.016694    -0.313061   \n",
       "2  -0.026454   0.369157   0.098631  ...     0.027988    -0.165158   \n",
       "3   0.028596   0.250725   0.000943  ...     0.065428     0.033266   \n",
       "4  -0.033724   0.399281   0.078976  ...     0.038849    -0.128436   \n",
       "\n",
       "   feature_760  feature_761  feature_762  feature_763  feature_764   \n",
       "0     0.030843     0.220228    -0.002753    -0.044868    -0.083309  \\\n",
       "1     0.206523     0.293353    -0.120235     0.003004    -0.026881   \n",
       "2    -0.019983     0.228936    -0.010385    -0.044965    -0.089852   \n",
       "3    -0.341756     0.153609     0.139355    -0.052577    -0.161805   \n",
       "4    -0.005195     0.239489    -0.026300    -0.040773    -0.107147   \n",
       "\n",
       "   feature_765  feature_766  feature_767  \n",
       "0     0.076162    -0.344506    -0.012195  \n",
       "1     0.008423    -0.385576     0.023437  \n",
       "2     0.107745    -0.332285    -0.018265  \n",
       "3     0.319533    -0.246552    -0.104527  \n",
       "4     0.124502    -0.341689    -0.004925  \n",
       "\n",
       "[5 rows x 770 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e48acad3-aa31-4049-badf-ab1552f4ef74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231128_213051\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 600s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231128_213051\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   246.90 GB / 509.72 GB (48.4%)\n",
      "Train Data Rows:    26128\n",
      "Train Data Columns: 769\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5180.92 MB\n",
      "\tTrain Data (Original)  Memory Usage: 160.74 MB (3.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 768 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\t\t('int', [])   :   1 | ['pid']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 768 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\t\t('int', [])   :   1 | ['pid']\n",
      "\t2.6s = Fit runtime\n",
      "\t769 features in original data used to generate 769 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 160.74 MB (3.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 3.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 596.9s of the 596.89s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 0.289 GB out of 5.211 GB available memory (27.764%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=0.33 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\tNot enough memory to train KNeighborsUnif_BAG_L1... Skipping this model.\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 595.81s of the 595.81s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 0.289 GB out of 5.245 GB available memory (27.584%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=0.33 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\tNot enough memory to train KNeighborsDist_BAG_L1... Skipping this model.\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 594.7s of the 594.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==0.8.2`.\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 592.45s of the 592.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==0.8.2`.\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 590.5s of the 590.49s of remaining time.\n",
      "\t0.7597\t = Validation score   (roc_auc)\n",
      "\t32.76s\t = Training   runtime\n",
      "\t6.42s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 550.56s of the 550.56s of remaining time.\n",
      "\t0.7656\t = Validation score   (roc_auc)\n",
      "\t53.03s\t = Training   runtime\n",
      "\t6.39s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 490.45s of the 490.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==0.8.2`.\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 488.79s of the 488.79s of remaining time.\n",
      "\t0.7629\t = Validation score   (roc_auc)\n",
      "\t9.21s\t = Training   runtime\n",
      "\t6.65s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 472.16s of the 472.16s of remaining time.\n",
      "\t0.7638\t = Validation score   (roc_auc)\n",
      "\t9.6s\t = Training   runtime\n",
      "\t6.62s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 455.14s of the 455.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==0.8.2`. \n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 453.47s of the 453.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==0.8.2`.\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 451.03s of the 451.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7713\t = Validation score   (roc_auc)\n",
      "\t327.19s\t = Training   runtime\n",
      "\t4.7s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 117.96s of the 117.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==0.8.2`.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 116.28s of remaining time.\n",
      "\t0.7721\t = Validation score   (roc_auc)\n",
      "\t1.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 485.29s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231128_213051\\\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 40min 10s\n",
      "Wall time: 8min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x2915fd12f70>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "predictor = TabularPredictor(\n",
    "    label = 'label', # response variable\n",
    "    problem_type = 'binary', \n",
    "    eval_metric = 'roc_auc' # other options listed: https://auto.gluon.ai/stable/api/autogluon.tabular.TabularPredictor.html\n",
    ")\n",
    "\n",
    "predictor.fit(\n",
    "    presets = 'best_quality',\n",
    "    train_data = train_df,\n",
    "    time_limit = 60*10,\n",
    "    # excluded_model_types = ['KNN','NN_TORCH','FASTAI'] # Optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ee1df27-9656-455d-8c1c-c41853d5f70b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      WeightedEnsemble_L2   0.772078      17.705130  391.154369                0.000000           1.339336            2       True          6\n",
      "1    NeuralNetTorch_BAG_L1   0.771330       4.700446  327.186492                4.700446         327.186492            1       True          5\n",
      "2  RandomForestEntr_BAG_L1   0.765574       6.385236   53.032672                6.385236          53.032672            1       True          2\n",
      "3    ExtraTreesEntr_BAG_L1   0.763830       6.619447    9.595870                6.619447           9.595870            1       True          4\n",
      "4    ExtraTreesGini_BAG_L1   0.762949       6.654202    9.213769                6.654202           9.213769            1       True          3\n",
      "5  RandomForestGini_BAG_L1   0.759747       6.421000   32.764759                6.421000          32.764759            1       True          1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.772078</td>\n",
       "      <td>17.705130</td>\n",
       "      <td>391.154369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.339336</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.771330</td>\n",
       "      <td>4.700446</td>\n",
       "      <td>327.186492</td>\n",
       "      <td>4.700446</td>\n",
       "      <td>327.186492</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.765574</td>\n",
       "      <td>6.385236</td>\n",
       "      <td>53.032672</td>\n",
       "      <td>6.385236</td>\n",
       "      <td>53.032672</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1</td>\n",
       "      <td>0.763830</td>\n",
       "      <td>6.619447</td>\n",
       "      <td>9.595870</td>\n",
       "      <td>6.619447</td>\n",
       "      <td>9.595870</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.762949</td>\n",
       "      <td>6.654202</td>\n",
       "      <td>9.213769</td>\n",
       "      <td>6.654202</td>\n",
       "      <td>9.213769</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.759747</td>\n",
       "      <td>6.421000</td>\n",
       "      <td>32.764759</td>\n",
       "      <td>6.421000</td>\n",
       "      <td>32.764759</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  score_val  pred_time_val    fit_time   \n",
       "0      WeightedEnsemble_L2   0.772078      17.705130  391.154369  \\\n",
       "1    NeuralNetTorch_BAG_L1   0.771330       4.700446  327.186492   \n",
       "2  RandomForestEntr_BAG_L1   0.765574       6.385236   53.032672   \n",
       "3    ExtraTreesEntr_BAG_L1   0.763830       6.619447    9.595870   \n",
       "4    ExtraTreesGini_BAG_L1   0.762949       6.654202    9.213769   \n",
       "5  RandomForestGini_BAG_L1   0.759747       6.421000   32.764759   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer   \n",
       "0                0.000000           1.339336            2       True  \\\n",
       "1                4.700446         327.186492            1       True   \n",
       "2                6.385236          53.032672            1       True   \n",
       "3                6.619447           9.595870            1       True   \n",
       "4                6.654202           9.213769            1       True   \n",
       "5                6.421000          32.764759            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          6  \n",
       "1          5  \n",
       "2          2  \n",
       "3          4  \n",
       "4          3  \n",
       "5          1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20370304-5535-4ce5-ac03-3744daf1f05c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.set_model_best('WeightedEnsemble_L2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
